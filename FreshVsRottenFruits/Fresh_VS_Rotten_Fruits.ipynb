{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### This is a Multi-class classifier for different types of fresh and rotten fruits\n",
        "\n",
        "\n",
        "1. Fresh Apple\n",
        "2. Fresh Orange\n",
        "3. Rotten Apple\n",
        "4. Rotten Orange\n",
        "\n"
      ],
      "metadata": {
        "id": "OfMKiMX6PsnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading dataset from google drive"
      ],
      "metadata": {
        "id": "ViWmlz4-xoKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l40LxNdwyqZ",
        "outputId": "c9c99974-1a0d-494a-f006-7d68e2270ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TXwVYM3K69ocfj1t8wCS31OjoA0ajlRl\n",
            "To: /content/fruits.zip\n",
            "100% 981M/981M [00:15<00:00, 64.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1TXwVYM3K69ocfj1t8wCS31OjoA0ajlRl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting zip file"
      ],
      "metadata": {
        "id": "HDyxPKiLxt4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = './fruits.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('.')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "RYz5-BDlxL3X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting directories"
      ],
      "metadata": {
        "id": "kK1GRnlnxyeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_dir = os.path.join('./fruits/train')\n",
        "validation_dir = os.path.join('./fruits/validation')"
      ],
      "metadata": {
        "id": "lfyDBTQNxMpo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing and compiling the model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_yZuxBsEzxNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "mrf9Fb6zytSo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XvfAjReF3ZqV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the ImageDataGenerator"
      ],
      "metadata": {
        "id": "TL02Yst33nIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Normalizing images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(300, 300),\n",
        "        batch_size=126,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_gen = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(300, 300),\n",
        "        batch_size=126,\n",
        "        class_mode='categorical')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT0DaPNL3qWC",
        "outputId": "629a9cca-fb9d-4b91-8468-9bac78882e96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5790 images belonging to 4 classes.\n",
            "Found 1297 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "wxT_SZH15Kyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=20,\n",
        "    epochs=25,\n",
        "    verbose=1,\n",
        "    validation_data=validation_gen,\n",
        "    validation_steps=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA6BCPjM5Oc-",
        "outputId": "e91afa80-898f-4fb7-a045-6188d3bf35dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "20/20 [==============================] - 48s 1s/step - loss: 1.7513 - accuracy: 0.2967 - val_loss: 1.2437 - val_accuracy: 0.4524\n",
            "Epoch 2/25\n",
            "20/20 [==============================] - 19s 918ms/step - loss: 1.3802 - accuracy: 0.4075 - val_loss: 1.1426 - val_accuracy: 0.5026\n",
            "Epoch 3/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 1.2224 - accuracy: 0.4599 - val_loss: 1.0930 - val_accuracy: 0.5556\n",
            "Epoch 4/25\n",
            "20/20 [==============================] - 18s 902ms/step - loss: 1.0841 - accuracy: 0.5742 - val_loss: 0.9335 - val_accuracy: 0.5979\n",
            "Epoch 5/25\n",
            "20/20 [==============================] - 18s 909ms/step - loss: 0.8890 - accuracy: 0.6786 - val_loss: 0.8271 - val_accuracy: 0.6296\n",
            "Epoch 6/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.7002 - accuracy: 0.7310 - val_loss: 0.8019 - val_accuracy: 0.7063\n",
            "Epoch 7/25\n",
            "20/20 [==============================] - 18s 910ms/step - loss: 0.7210 - accuracy: 0.7242 - val_loss: 0.7898 - val_accuracy: 0.6799\n",
            "Epoch 8/25\n",
            "20/20 [==============================] - 19s 932ms/step - loss: 0.5768 - accuracy: 0.7757 - val_loss: 0.6126 - val_accuracy: 0.7328\n",
            "Epoch 9/25\n",
            "20/20 [==============================] - 18s 902ms/step - loss: 0.5566 - accuracy: 0.7774 - val_loss: 0.7400 - val_accuracy: 0.7143\n",
            "Epoch 10/25\n",
            "20/20 [==============================] - 19s 904ms/step - loss: 0.5581 - accuracy: 0.7913 - val_loss: 0.7068 - val_accuracy: 0.7275\n",
            "Epoch 11/25\n",
            "20/20 [==============================] - 19s 934ms/step - loss: 0.4815 - accuracy: 0.8131 - val_loss: 0.7760 - val_accuracy: 0.7116\n",
            "Epoch 12/25\n",
            "20/20 [==============================] - 18s 908ms/step - loss: 0.5179 - accuracy: 0.8130 - val_loss: 0.7356 - val_accuracy: 0.7116\n",
            "Epoch 13/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.4489 - accuracy: 0.8290 - val_loss: 0.4340 - val_accuracy: 0.8439\n",
            "Epoch 14/25\n",
            "20/20 [==============================] - 19s 922ms/step - loss: 0.4663 - accuracy: 0.8302 - val_loss: 0.6543 - val_accuracy: 0.7698\n",
            "Epoch 15/25\n",
            "20/20 [==============================] - 19s 945ms/step - loss: 0.4729 - accuracy: 0.8250 - val_loss: 0.6264 - val_accuracy: 0.7513\n",
            "Epoch 16/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.4372 - accuracy: 0.8317 - val_loss: 0.5500 - val_accuracy: 0.7619\n",
            "Epoch 17/25\n",
            "20/20 [==============================] - 18s 903ms/step - loss: 0.3665 - accuracy: 0.8620 - val_loss: 0.5303 - val_accuracy: 0.8069\n",
            "Epoch 18/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.3818 - accuracy: 0.8544 - val_loss: 0.4187 - val_accuracy: 0.8439\n",
            "Epoch 19/25\n",
            "20/20 [==============================] - 18s 897ms/step - loss: 0.3529 - accuracy: 0.8719 - val_loss: 0.4115 - val_accuracy: 0.8519\n",
            "Epoch 20/25\n",
            "20/20 [==============================] - 19s 933ms/step - loss: 0.3356 - accuracy: 0.8794 - val_loss: 0.4483 - val_accuracy: 0.8519\n",
            "Epoch 21/25\n",
            "20/20 [==============================] - 18s 907ms/step - loss: 0.2825 - accuracy: 0.8925 - val_loss: 0.7584 - val_accuracy: 0.7143\n",
            "Epoch 22/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.3036 - accuracy: 0.8854 - val_loss: 0.5461 - val_accuracy: 0.8201\n",
            "Epoch 23/25\n",
            "20/20 [==============================] - 18s 915ms/step - loss: 0.2513 - accuracy: 0.8994 - val_loss: 0.3635 - val_accuracy: 0.8677\n",
            "Epoch 24/25\n",
            "20/20 [==============================] - 19s 952ms/step - loss: 0.3671 - accuracy: 0.8885 - val_loss: 0.4058 - val_accuracy: 0.8677\n",
            "Epoch 25/25\n",
            "20/20 [==============================] - 19s 930ms/step - loss: 0.2101 - accuracy: 0.9204 - val_loss: 1.0330 - val_accuracy: 0.7011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can upload any image here to test the model"
      ],
      "metadata": {
        "id": "8TnH10aEQOrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(300, 300))\n",
        "  y = img_to_array(img)\n",
        "  y = np.expand_dims(y, axis=0)\n",
        "\n",
        "  images = np.vstack([y])\n",
        "  classes = model.predict(images, batch_size=1)\n",
        "  print(fn)\n",
        "  classes = classes.flatten()\n",
        "\n",
        "  mx = 0.0\n",
        "  mxi = classes.argmax()\n",
        "  print(classes)\n",
        "  if(mxi == 0):\n",
        "    print(\"Fresh Apple\")\n",
        "  elif(mxi == 1):\n",
        "    print(\"Fresh Orange\")\n",
        "  elif(mxi == 2):\n",
        "    print(\"Rotten Apple\")\n",
        "  else:\n",
        "    print(\"Rotten Orange\")"
      ],
      "metadata": {
        "id": "CSkxtil88APh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}